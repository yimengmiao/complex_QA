import os
import json
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from collections import defaultdict
import re

# === é…ç½® ===
PAPER_DIR = "papers"
VECTOR_DIR = "vector"
INPUT_JSON = "multi_choice_questions.json"
OUTPUT_JSON = "deepseek_output_with_answers.json"

# === LLM é…ç½® ===
os.environ["DASHSCOPE_API_KEY"] = "sk-693e67f2dfeb4044a2afaeca4f226e85"
llm = ChatOpenAI(
    model="qwen-plus",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# === åµŒå…¥æ¨¡å‹ ===todo:æ›¿æ¢æˆopenaiçš„embedding
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# === åŠ è½½åŸå§‹é—®é¢˜JSON ===
with open(INPUT_JSON, "r", encoding="utf-8") as f:
    questions_data = json.load(f)

# === å°†é—®é¢˜æŒ‰ paper_id åˆ†ç»„ ===
questions_by_paper = defaultdict(list)
for item in questions_data:
    questions_by_paper[item["paper_id"]].append(item)

# === ä¸»å¾ªç¯ï¼šå¤„ç†æ¯ç¯‡è®ºæ–‡ ===
for paper_id, questions in questions_by_paper.items():

    # âœ… è·³è¿‡å·²å¤„ç†çš„ paper_idï¼ˆå¦‚ 0~25 æˆ–éæ³•IDï¼‰
    if not paper_id.isdigit() or int(paper_id) < 26:
        print(f"â­ï¸ è·³è¿‡å·²å¤„ç†çš„ paper_id: {paper_id}")
        continue

    paper_vector_path = os.path.join(VECTOR_DIR, paper_id)

    # âœ… è‹¥å‘é‡ç›®å½•å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ embeddingï¼‰
    if os.path.exists(paper_vector_path) and os.listdir(paper_vector_path):
        print(f"â­ï¸ å·²å­˜åœ¨å‘é‡ç´¢å¼•ï¼Œè·³è¿‡ï¼š{paper_id}")
        continue

    try:
        paper_folder = os.path.join(PAPER_DIR, paper_id)
        pdf_file = [f for f in os.listdir(paper_folder) if f.endswith(".pdf")][0]
        pdf_path = os.path.join(paper_folder, pdf_file)
        print(f"ğŸ“„ æ­£åœ¨å¤„ç†è®ºæ–‡ï¼š{pdf_path}")
    except Exception as e:
        print(f"âŒ æ‰¾ä¸åˆ° {paper_id} çš„ PDF æ–‡ä»¶ï¼š{e}")
        continue

    try:
        # 1. åŠ è½½å¹¶åˆ‡åˆ† PDF
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        docs = splitter.split_documents(documents)

        # âœ… 2. æ¸…æ´—éæ³•æ–‡æ®µ
        docs = [doc for doc in docs if isinstance(doc.page_content, str) and doc.page_content.strip()]
        if not docs:
            print(f"âš ï¸ æ–‡æ¡£ä¸ºç©ºæˆ–æ— æœ‰æ•ˆæ®µè½ï¼š{paper_id}")
            continue

        # åœ¨è¿™é‡Œæ‰“å°å‡ºæ¯ä¸ªæ–‡æ¡£çš„å†…å®¹ï¼ŒæŸ¥çœ‹æå–çš„æ–‡æœ¬
        for idx, doc in enumerate(docs):
            print(f"=== æ–‡æ¡£ {idx + 1} ===")
            print(doc.page_content[:500])  # æ‰“å°æ¯ä¸ªæ–‡æ¡£çš„å‰500ä¸ªå­—ç¬¦
            print("\n" + "=" * 50 + "\n")

        # âœ… 3. æ„å»ºå‘é‡æ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        vectorstore = Chroma.from_documents(
            docs,
            embedding=embedding,
            persist_directory=paper_vector_path
        )
        retriever = vectorstore.as_retriever()

        # âœ… 4. åˆ›å»ºé—®ç­”é“¾
        qa = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            return_source_documents=False
        )

        # âœ… 5. å›ç­”æ¯ä¸ªé—®é¢˜
        for q in questions:
            question_text = q.get("question", "").strip()
            if not question_text:
                continue

            print(f"ğŸ” æé—®ï¼š{question_text[:80]}...")
            try:
                response = qa.invoke({"query": question_text})
                answer_text = response.get("result", "")
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼š{e}")
                answer_text = ""

            matches = re.findall(r"[A-D]", answer_text.upper())
            selected = "".join(sorted(set(matches)))
            q["correct_answer"] = selected if selected else "N/A"

            print(f"âœ… æ¨¡å‹åˆ¤æ–­ç­”æ¡ˆï¼š{selected} | åŸå§‹å›å¤ï¼š{answer_text.strip()}\n")

    except Exception as e:
        print(f"âŒ å¤„ç† {paper_id} æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
        continue

# === ä¿å­˜è¾“å‡ºç»“æœ ===
with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
    json.dump(questions_data, f, indent=2, ensure_ascii=False)

print(f"\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜è‡³ï¼š{OUTPUT_JSON}")
